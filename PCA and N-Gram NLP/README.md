## Principle Component Analysis and N-Gram Natural Language Processing

This project covered both Principle Component Analysis and N-Gram Natural language Processing. The functional code for both techniques is contained in the program "pca.py". The PCA portion takes image vectors as an input, reduces their dimensionality using their top k eigenvectors, then projects them back into their original dimensionality. An example of this process can be seen in "pca.png". The NLP portion of the project trains an N-gram model on an input text, with N being specified by the method input, and then generates a length of text based on the trained model. The generated text is not particularly impressive or useful as the word size used is a single character, but the code does function as intended.

## Provided by instructors:

image dataset for processing (celeba_60x50.npy and celeba_218x178x3.npy)

N-Gram test and debugging tool(test_ngram.py)

method structure and headers in pca.py

## personal contributions:

Implementation of all methods in pca.py
